{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1a6910-3ce7-4435-abdf-d604c8b6705f",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33921a-03b3-4993-ae58-409c0609efc6",
   "metadata": {},
   "source": [
    "The objective of assignment 3 is to assess the extent to which dataset size and hyperparameter tuning affects the performance of prognostic models.\n",
    " \n",
    "The learning objectives are: (1) how performance is affected by sample size, (2) how this varies by modeling technique, and (3) when hyperparameter tuning is most useful.\n",
    "\n",
    "You will be given a large dataset and are asked to sample datasets of various sizes from it. For each sample train a machine learning model. Then plot the relationship between the sample size and the model performance. You should expect to see a power curve with better performance with larger datasets.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The workflow of this assignment is as following:\n",
    "\n",
    "1. The code to load and data preprocessing, including predictor selection, will be given, please do not change the corresponding code.\n",
    "2. We will generate a vector of integers as the sample sizes of each subset (code will be provided).\n",
    "3. Then for each dataset:\n",
    "    1. Train CART and LGBM models, with and without tuning, on __all of the records in the dataset__ with 5-fold nested CV to establish a baseline.\n",
    "    2. Train CART and LGBM models, with and without tuning, on __each subset with different sample size__ with 5-fold nested CV.\n",
    "    \n",
    "    (These two steps don't have to be in this particular order. See below.)\n",
    "    \n",
    "4. You will complete the function at the top to complete these steps. \n",
    "5. Plot the the relationship between sample size and model performance (AUC and scaled Brier score) and answer the questions based on your plots. Elaborate your answer by providing the thought process.\n",
    "\n",
    "## Some notes\n",
    "\n",
    "The dataset used in this assignement is a public dataset, and there is some information about the dataset in the help and in the attached document. The dataset is: faers (FDA adverse drug events). The help file documents the binary prediction models that can be trained.\n",
    "\n",
    "Based on the previous assignment, you should only be using nested CV (no need for repeated nested CV because as we saw the variation is very small with nested CV and therefore the repeated part does not really add much value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b5434-f289-4686-84d4-79461890b846",
   "metadata": {},
   "source": [
    "## Changes of functions in the updated `sdgm` package\n",
    "\n",
    "Before you start working on the main question, please note that we have updated the `sdgm` package and below are some important changes. Read carefully and you will need to use these affected functions in this assignment.\n",
    "\n",
    "### Model building functions\n",
    "\n",
    "In the updated `sdgm` packages, the functions to build models have been updated to add a new parameter called `tune` to control whether to tune the model (default = T), you can use `tune = F` to turn off hyperparameter tuning when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8430a-e071-49a8-8185-3d1ae251c371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One example to show the changes. This applys to all the model building functions.\n",
    "?sdgm::cart.bestmodel.bin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d9c21-ce33-4e9f-a80d-2be09ab52fa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `nested.cv.bin` for nested CV\n",
    "\n",
    "In the updated version of `sgbm` package, there is a new function called `nested.cv.bin` that implements nested cv, see the help page below to see more details. We will use this function in this assignment.\n",
    "\n",
    "__Important note:__ With this `nested.cv.bin` function, you don't need to implement parallel computing yourself. There is a parameter called `par` to control if the outer loop should be parallelized, and its default value is `T`. So without changing it, the program will parallelize the outer loop automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2d032-8a9a-48fe-9e2d-b9b4a6a5d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?sdgm::nested.cv.bin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d81a96-75b4-4963-be27-63070d1f6ac7",
   "metadata": {},
   "source": [
    "## Load useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290050d-e3ad-4fc6-a69e-cb0e759b43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(sdgm)\n",
    "library(dplyr)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de51215-c01d-4668-8c76-8a5c95869f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The dataset: `sdgm::faers` (FDA adverse events)\n",
    "\n",
    "For more details about this dataset, see below and the attached file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac605e3-dc3b-4eeb-8b12-4ab096f0d178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the help file of this dataset. It documents the binary prediction model \n",
    "# that can be trained from this dataset.\n",
    "?sdgm::faers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86c78f-3743-4b71-afe8-7595f7e7c0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this assignment, we will provide the data pre-processing steps (same as in the help file above). Please don't change code here.\n",
    "\n",
    "# get the dataset\n",
    "data<-sdgm::getdata(\"faers\")\n",
    "\n",
    "# create binary outcome\n",
    "data$status <- ifelse(data$outc_cod_0 == \"DE\", 1,\n",
    "                     ifelse(data$outc_cod_0 %in% c(\"CA\", \"DS\", \"HO\", \"LT\", \"OT\", \"RI\"), 0, NA))\n",
    "\n",
    "# transform event_dt into days\n",
    "data$date <- as.Date(as.character(data$event_dt), format = \"%Y%m%d\")\n",
    "data$days <- as.numeric(as.Date(\"2020-01-01\") - data$date)\n",
    "\n",
    "data$weight                               <- data$wt\n",
    "data$weight[which(data$wt_cod == \"LBS\")]  <- data$wt[which(data$wt_cod == \"LBS\")] * 0.45359237\n",
    "\n",
    "data$age_yr                               <- data$age\n",
    "data$age_yr[which(data$age_cod == \"DEC\")] <- data$age[which(data$age_cod == \"DEC\")] * 10\n",
    "data$age_yr[which(data$age_cod == \"DY\")]  <- data$age[which(data$age_cod == \"DY\")] / 365\n",
    "data$age_yr[which(data$age_cod == \"HR\")]  <- data$age[which(data$age_cod == \"HR\")] / (24*365)\n",
    "data$age_yr[which(data$age_cod == \"MON\")] <- data$age[which(data$age_cod == \"MON\")] / 12\n",
    "data$age_yr[which(data$age_cod == \"WK\")]  <- data$age[which(data$age_cod == \"WK\")] / 52\n",
    "\n",
    "data$age_yr                               <- ifelse(data$age_yr >= 150, NA, data$age_yr)\n",
    "\n",
    "# transform sex into factor\n",
    "data$sex <- factor(data$sex) \n",
    "\n",
    "# select predictors (categorical)\n",
    "data$drug            <- as.factor(data$drugname_0)\n",
    "\n",
    "data$indi_pt         <- as.factor(data$indi_pt_0)\n",
    "\n",
    "# subset dataset\n",
    "cols_select <- c(\"status\", \"days\", \"sex\", \"age_yr\", \"weight\", \"drug\", \"indi_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728abcf-f951-41fe-a952-0c064b104061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note here we need to transform the dataset from tibble to dataframe to avoid some issues\n",
    "full_data <- as.data.frame(data %>% select(all_of(cols_select)))\n",
    "\n",
    "# have a look\n",
    "dim(full_data)\n",
    "summary(full_data)\n",
    "str(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123ea32-df50-40a7-819c-972833d62e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the outcome variable\n",
    "voutcome <- \"Your answer\"\n",
    "\n",
    "table(full_data[,voutcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552c438-cadf-4c3c-9296-b5a3d31f1f31",
   "metadata": {},
   "source": [
    "## Question 1: Describe the missingness pattern\n",
    "\n",
    "Using \"Lecture 6 - Missingness Patterns on CCHS 2023 - v2.ipynb\" as your reference, describe the missingness pattern in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84f16b-8526-4a85-bdd1-55888c2e0bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Describe the missingness pattern\n",
    "\"Your answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7947d5-d914-4620-a6c8-dd686cd013a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "You may have noticed that the data has three potential issues:\n",
    "1. It has a lot of NAs. The current implementation of CART and LGBM in the `sdgm` package can deal with missingness in predictors, so you don't need to worry about it. However, we need to filter our the `NA`s in the __outcome variable__.\n",
    "2. Variables like `drug` and `indi_pt` have a lot of categories, i.e., very high cardinality. In this assignment, you will see that LGBM and CART are able to handle high cardinality variables. They both implement a mean target encoding scheme for a binary outcome.\n",
    "3. The outcome variable in this dataset is highly imbalanced. However, since the learning objectives in this assignment is to assess the influence of dataset size and hyperparameter tuning, we will ignore the imbalance issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b70f1d-2ff8-442a-8b5e-6ea03acd66a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out NAs in the outcome variable\n",
    "full_data <- \"Your answer\"\n",
    "\n",
    "# have a look\n",
    "dim(full_data)\n",
    "summary(full_data)\n",
    "str(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88dd1b-50bf-4bec-9907-469f86ce70a4",
   "metadata": {},
   "source": [
    "## Define a vector of integers as sample sizes of the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071496ef-3292-4e83-a50e-ba5188fcdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10) # NEED TO BE ADDED\n",
    "b<-rnorm(1, 1.5,0.005) \n",
    "set_sizes<-round(b^(10:32))\n",
    "\n",
    "# make sure the subset size doesn't exceed the whole data size\n",
    "size_whole <- nrow(full_data)\n",
    "set_sizes <- set_sizes[set_sizes < size_whole]\n",
    "\n",
    "# Add the full sample size at the end\n",
    "set_sizes <- c(set_sizes, size_whole)\n",
    "set_sizes\n",
    "\n",
    "# total number of subsets including the whole dataset\n",
    "n_set <- length(set_sizes)\n",
    "n_set\n",
    "\n",
    "ind_sizes <- 1: length(n_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c0dc1-e4f9-477a-b6de-b815a1837fe6",
   "metadata": {},
   "source": [
    "## Question 2 (optional - bonus): More subsets to smooth out the final plot\n",
    "In the current set up in the above cell, you'll have about 22 subsets with different sample sizes, including the whole dataset. You'll get bonus points if you can increase the number of subsets in a reasonable way to make the final plot smoother.\n",
    "\n",
    "If you choose to work on this bonus question, please just make changes in the above cell. The change will be reflected by `set_sizes`, `n_set`, and the final plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd342897-68f3-490b-bce5-ff9bd6352485",
   "metadata": {},
   "source": [
    "## Question 3: Building and evaluating 4 models (`cart` and `lgbm`, with and without tuning) on all the subsets\n",
    "\n",
    "For reference, please see \"Lecture 4 - Nested K-cross validation of CART on CCHS.ipynb\" and your code for assignment 2.\n",
    "\n",
    "Use the code below to control `n_iter` throughout the assignment. You can set it as `n_iter <- 1` when you develop and debug the code. Then set it as `n_iter <- 20` for the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297d843-da75-4e70-bd6a-58380d69c776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_iter <- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e4f60-a309-4e1d-a82c-573463ee25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Building 4 models for each subset ==================\n",
    "\n",
    "# loop through all subsets including the whole dataset\n",
    "res <- sapply(set_sizes, function(size) { \n",
    "    \n",
    "    # slice the data using the current sample size: size\n",
    "    sub_data <- full_data %>% slice_sample(n=size)\n",
    "\n",
    "    # build and evaluate 4 models\n",
    "    res.model <- sapply(1:4, function(i_model) {\n",
    "        # name of file\n",
    "        file_name <- paste0(\"result.\",nrow(sub_data), \".\", i_model, \".rds\")\n",
    "        \n",
    "        # check if file already exists\n",
    "        if (file.exists(name_file)) { # exist, read the file\n",
    "           res_vec <- readRDS(file_name) \n",
    "        } else { # not exist, run the code\n",
    "            # build and evaluate \n",
    "            \"Your answer\"\n",
    "\n",
    "            # collect results\n",
    "            res_vec <- \"Your answer\"\n",
    "\n",
    "            # save it to a file\n",
    "            saveRDS(res_vec, file = file_name)\n",
    "        }\n",
    "        # return results\n",
    "        res_vec\n",
    "    })\n",
    "\n",
    "    # return \n",
    "    res.model\n",
    "})\n",
    "\n",
    "# have a look\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733d08b-adad-4248-9480-cf8bf5dc9e8d",
   "metadata": {},
   "source": [
    "In order to generate the plots using the code provided below, you'll need to organize your result `res` into a dataframe with five variables: \n",
    "\n",
    "1. `size`: sample size of each subset\n",
    "2. `model`: a categorical variable of `cart` and `lgbm`\n",
    "3. `tune`: a categorical variable of `with tuning` and `without tuning`\n",
    "4. `auc`: the AUC value\n",
    "5. `brier`: the brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11430fd8-23af-4168-8667-705ded56433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- re-organize `res` and save it as a data.frame -------- \n",
    "df.res <- \"Your answer\"\n",
    "\n",
    "# have a look at the results dataframe\n",
    "df.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fbda7-406e-48c2-ae8f-4768c05412fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change plot size to 18 * 6\n",
    "options(repr.plot.width=18, repr.plot.height=6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8b5d9-9f91-406b-bce5-6528e3f29a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot of auc \n",
    "ggplot(df.res, aes(size, auc, color = tune)) +\n",
    "    geom_point(size = 3) +\n",
    "    geom_path()+\n",
    "    geom_hline(data = df.res %>% filter(size == max(df.res$size)), \n",
    "               aes(yintercept = auc, color = tune), linetype = \"dashed\") +\n",
    "    facet_wrap(~model)+\n",
    "    labs(x = \"Sample size\",\n",
    "         y = \"AUC value\",\n",
    "         title = paste0(\"faers: FDA adverse events, n_iter = \", n_iter)) +\n",
    "    theme(text = element_text(size = 20),\n",
    "          legend.title = element_blank())\n",
    "\n",
    "# Plot of brier \n",
    "ggplot(df.res, aes(size, brier, color = tune)) +\n",
    "    geom_point(size = 3) +\n",
    "    geom_path()+\n",
    "    geom_hline(data = df.res %>% filter(size == max(df.res$size)), \n",
    "               aes(yintercept = brier, color = tune), linetype = \"dashed\") +\n",
    "    facet_wrap(~model) +\n",
    "    labs(x = \"Sample size\",\n",
    "         y = \"Brier score\") +\n",
    "    theme(text = element_text(size = 20),\n",
    "          legend.title = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99c8d4-3f27-4fee-a88c-73d9fb49308f",
   "metadata": {},
   "source": [
    "## Question 4: How large does the dataset need to be to get reasonable discrimination and calibration ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b68f0b-eff7-4eee-b2e3-e7b3ced1b349",
   "metadata": {},
   "source": [
    "## Question 5: Does tuning affect the discrimination and calibration results ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a52ca-4b93-4215-9577-ce67ec44419a",
   "metadata": {},
   "source": [
    "## Question 6: How do tuning and sample size interact in influencing the discrimination and calibration results ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037d483-89fd-4ce3-b307-bfe9bb5383e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Congratulation! You have completed the Assignment 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
